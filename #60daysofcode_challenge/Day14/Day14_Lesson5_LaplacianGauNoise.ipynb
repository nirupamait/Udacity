{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we actually use epsilon and delta?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Randomized mechanism :: A function with random noise added to its inputs,outputs and/or inner workings.\n",
    "This randomized mechanism should satisfy certain degree of DP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Global DP :: We are adding noise to the output and how much noise should we add.\n",
    "We are going to add minimum amount required, to satisfy a certain level of epsilon and delta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy Budget?\n",
    "How much epsilon or delta leakage we allow for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two types of noise, we can add::\n",
    "Gaussian\n",
    "Laplacian"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Laplacian noise works better but technically, both are still valid and can give us varying levels of epsilon-delta privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much noise should we add?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The amount of noise that we should add to the output of query if function of four things.\n",
    "1)Type of noise(Gaussian/Laplacian) :: Amount of noise that we are adding depends on the type of noise that we are adding.\n",
    "2)Sensitivity of query that we are using to query the db.\n",
    "3)Desired epsilon\n",
    "4)Desired delta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Therefore, for each type of noise that we are adding, we have a different way of calculating how much noise to add as a function of the sensitivity of the query, to meet a certain epsilon-delta constraint. Each noise type has specific function, which tells us how much noise to add given a certain sensitivity, epsilon and delta."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Laplacian noise takes input parameter beta ,which determines how significant the noise is.\n",
    "b=sensitivity of the query/epsilon that we want to achieve\n",
    "Delta is always zero for laplacian noise.Delta is probability that we leak more than this amount of noise.\n",
    "Laplacian guarantees that we will not leak more than this amount of noise.\n",
    "\n",
    "Laplacian noise increase or decrease according to scale parameter beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Differentially Private Query Project"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We are going to put together Laplacian mechanism. We are going to see that the way in which we choose our beta,\n",
    "the way in which we formulate the amount of noise create, is adjusted based on the sensitivity of the mean and sum,\n",
    "such that for mean, we have smaller amount of sensitivity, we adding smaller amount of noise."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets epsilon budget for our single query is going to be 0.5,\n",
    "As we make epsilon smaller, we have to make increase the amount of noise that we have to add in orde to be able to get\n",
    "this level of privacy protection."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Laplace Distribution/Double Exponential Distribution ::\n",
    "\n",
    "Link:: https://www.itl.nist.gov/div898/handbook/eda/section3/eda366c.htm\n",
    "\n",
    "The general formula for the probability density function of the double exponential distribution is\n",
    "f(x)=e−∣x−μ/β∣2β\n",
    "where μ is the location parameter and β is the scale parameter.\n",
    "\n",
    "What is location and scale paramter?\n",
    "https://www.itl.nist.gov/div898/handbook/eda/section3/eda364.htm\n",
    "The effect of the location parameter is to translate the graph, relative to the standard normal distribution.\n",
    "The effect of the scale parameter is to stretch out the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is The Laplace Mechanism??\n",
    "\n",
    "Link:: https://stats.stackexchange.com/questions/223494/what-is-meant-by-laplace-noise?noredirect=1\n",
    "The Laplace Mechanism. Given any function f:N|X|→Rk, the Laplace mechanism is defined as: ML(x,f(⋅),ϵ)=f(x)+(Y1,...,Yk) where Y are i.i.d. random variables drawn from Lap(Δf/ϵ)\n",
    "To generate Y ( X ), a common choice is to use a Laplace distribution with zero mean and Δ ( f ) /ε scale parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Laplace random variables::\n",
    "https://www.johndcook.com/blog/2018/03/13/generating-laplace-random-variables/\n",
    "\n",
    "Formula from scratch to generate Laplace values in Python::\n",
    "from math import log\n",
    "    from random import random\n",
    "\n",
    "    def exp_sample(mean): \n",
    "        return -mean*log(random())\n",
    "\n",
    "    def laplace(scale):\n",
    "        e1 = exp_sample(scale)\n",
    "        e2 = exp_sample(scale)\n",
    "        return e1 - e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques:\n",
    "Two types of noise, we can add::\n",
    "Gaussian\n",
    "Laplacian\n",
    "\n",
    "Why Laplacian noise is better than Gaussian?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ans\n",
    "Gogulaanand R  \n",
    "in laplacian noise we are almost always guranteed that the delta is 0\n",
    "\n",
    "Gogulaanand R \n",
    "there is no extra unaccounted privacy leak other than the epsilon\n",
    "\n",
    "Nirupama Singh  \n",
    "@Gogulaanand R Why delta is zero?If I agree that delta is zero, then it means that privacy leak will be less.?\n",
    "\n",
    "Tyler Yang \n",
    "@Nirupama Singh I can't explain why the delta is zero, but the mathematical proof can be found in the book _The Algorithmic Foundation of Differential Privacy_. The author also explains why Gaussian noise *DO* have delta.\n",
    "\n",
    "When delta is zero, there is no chance for accidental information leak that is bigger than epsilon—bigger delta means higher probability of leaking more information than what you would expect with the epsilon. (edited)\n",
    "\n",
    "Nirupama Singh \n",
    "Thanks @Tyler Yang\n",
    "\n",
    "Prakhar Tripathi\n",
    "@Nirupama Singh Laplacian noise (also called biexponential) which has this pdf: Nonlinear estimators can provide a much more accurate estimate of the mean of a stationary Laplacian random variable than the linear average [6]. ... This implies that nonlinear filters should be better at removing uniform noise than Gaussian noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques\n",
    "In Laplaccian noise, beta=sensitivity of the query/epsilon that we want to achieve\n",
    "Why beta(scale parameter) is chosen as sensitivity of the query/epsilon that we want to achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ans\n",
    "Ateniola Oluwatobi Victor\n",
    "@Nirupama Singh, :wink:that is just how the formula for beta is in Laplacian noise. You can use the formula perfectly when trying to use differential privacy without knowing the proof of the formula.\n",
    "If you want to know the proof behind the formula and also behind so many other concepts in differential privacy, I suggest you read Cynthia Dwork's book: The Algorithmic foundations of differential privacy. The book is quite technical and you might not understand some mathematical concepts except you have a mathematics background.\n",
    "https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques\n",
    "Nirupama Singh\n",
    "In video, it is given that Delta is always zero for laplacian noise.\n",
    "Why delta is zero in Laplaccian noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ans\n",
    "Gogulaanand R \n",
    "for your query regarding why delta is zero, see this answer by @Rishi S Rao\n",
    "https://secureprivataischolar.slack.com/archives/CJCJJQ42W/p1562689042007400?thread_ts=1562687359.006900&cid=CJCJJQ42W\n",
    "Rishi S Rao\n",
    "this is quiet intense proof if your are not from math but if want to go through it, it is in the 3rd chapter of the text from Cynthia Dwork.\n",
    "From a thread in #l4_loc_glob_diff_priv | Yesterday at 9:47 PM | View reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques:\n",
    "Nirupama Singh\n",
    "Is Gaussian distribution means normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ans:\n",
    "Venkata Rathnam Muralidharan \n",
    "Yes.  Both are same.  The standard normal distribution is the different one where mean = 0, variance = 1 distribution condition will be maintained. (edited)\n",
    "\n",
    "Aarthi Alagammai \n",
    "yes normalized gaussian distribution is normal distribution\n",
    "\n",
    "David Fernando Jurado Blanco \n",
    "Within the realm of probability theory, they're the same.\n",
    "\n",
    "Deepak Sharma \n",
    "Yes they are, in statistics theory its very important as 95% of the data is between 2 standard deviation away from mean. Assuming that your mean is at the center of distribution. You can then create hypothesis for your arguments.\n",
    "\n",
    "Prakhar Tripathi \n",
    "@Nirupama Singh yes within probabab it is same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Create a Differentially Private Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a query function which sums over the database and adds just the right amount of noise such that it satisfies an epsilon constraint. Write a query for both \"sum\" and for \"mean\". Ensure that you use the correct sensitivity measures for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epsilon = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# the number of entries in our database\n",
    "num_entries = 5000\n",
    "\n",
    "db = torch.rand(num_entries) > 0.5\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_parallel_db(db, remove_index):\n",
    "\n",
    "    return torch.cat((db[0:remove_index], \n",
    "                      db[remove_index+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_parallel_dbs(db):\n",
    "\n",
    "    parallel_dbs = list()\n",
    "\n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db, i)\n",
    "        parallel_dbs.append(pdb)\n",
    "    \n",
    "    return parallel_dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_and_parallels(num_entries):\n",
    "    \n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    \n",
    "    return db, pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db, pdbs = create_db_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_mechanism(db, query, sensitivity):\n",
    "    \n",
    "    beta = sensitivity / epsilon\n",
    "    noise = torch.tensor(np.random.laplace(0, beta, 1))\n",
    "    \n",
    "    return query(db) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_query(db):\n",
    "    return torch.mean(db.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4857.2294], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_mechanism(db, sum_query, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.8954], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "laplacian_mechanism(db, mean_query, 1/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
